# **Chatbot RAG - Marco Aurelio** ğŸ›ï¸ğŸ¤–  
_A conversational AI chatbot based on Retrieval-Augmented Generation (RAG), inspired by the Stoic philosophy of Marcus Aurelius._
Robust and scalable RAG chatbot designed to integrate advanced AI capabilities for intelligent question-answering. This project leverages cutting-edge natural language processing (NLP) and vector search technologies to enhance the chatbot's accuracy and efficiency.

## **ğŸ“œ Overview**
Chatbot RAG is an AI-powered conversational assistant designed to emulate Marcus Aurelius' philosophy. It uses **FastAPI** for the backend, **LangChain** for retrieval-augmented generation (RAG), and is deployed across **Railway (backend)** and **GitHub Pages (frontend)**.

---

## **ğŸš€ Features**
âœ” **Retrieval-Augmented Generation (RAG):** Generates answers based on Marcus Aurelius' *Meditations*.  

âœ” **FastAPI Backend:** High-performance, asynchronous API framework for handling chatbot interactions.

âœ” **LangChain Integration:** Modular framework for integrating Large Language Models (LLMs) with external data sources.  

âœ” **Pinecone Vector Search:** Retrieves relevant quotes from *Meditations*.  

âœ” **Lightweight Frontend:** Deployed on GitHub Pages with a simple HTML/CSS/JS interface.  

âœ” Docker - Containerized deployment ensuring scalability and easy integration.

âœ” **Cloud Deployment:** Backend on Railway, frontend on GitHub Pages.  

---

## **ğŸ“‚ Repository Structure**
```
/chatbot-RAG
  â”œâ”€â”€ app/                  # Backend (FastAPI + LangChain)
  â”‚   â”œâ”€â”€ chatbot.py        # Chat logic (RAG + LangChain)
  â”‚   â”œâ”€â”€ config.py         # Environment variables
  â”‚   â”œâ”€â”€ embeddings.py     # Google AI embeddings
  â”‚   â”œâ”€â”€ main.py           # FastAPI app
  â”‚   â”œâ”€â”€ vectorstore.py    # Pinecone vector search
  â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
  â”œâ”€â”€ docs/                 # Frontend (GitHub Pages)
  â”‚   â”œâ”€â”€ index.html        # Web UI
  â”‚   â”œâ”€â”€ styles.css        # Chat styling
  â”‚   â”œâ”€â”€ script.js         # Handles chat interactions
  â”œâ”€â”€ .env                  # Environment variables (ignored)
  â”œâ”€â”€ .gitignore            # Ignore unnecessary files
  â”œâ”€â”€ Dockerfile            # Docker configuration for deployment
  â”œâ”€â”€ README.md             # Project documentation
```

---

## **ğŸ›  Installation**
### **1ï¸âƒ£ Clone the repository**
```bash
git clone https://github.com/FullFran/chatbot-RAG.git
cd chatbot-RAG
```

### **2ï¸âƒ£ Set up the backend**
#### **Using Docker (Recommended)**
```bash
docker build -t chatbot-rag .
docker run -p 8000:8000 chatbot-rag
```
#### **Manual Setup**
```bash
pip install -r app/requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

---

## **ğŸ“¡ Deployment**
### **Backend: Railway**
The backend is deployed on **Railway**. To redeploy, push changes to the `main` branch.
```bash
git add .
git commit -m "Updated backend"
git push origin main
```
Railway will automatically detect and deploy updates.

---

### **Frontend: GitHub Pages**
The frontend is served via **GitHub Pages**.  
To update, modify the files in the `docs/` folder and push changes.

---

## **ğŸ“Œ Usage**
1ï¸âƒ£ **Open the Chatbot:** [`https://fullfran.github.io/chatbot-RAG/`](https://fullfran.github.io/chatbot-RAG/)  

2ï¸âƒ£ **Type a question related to Stoicism.**  

3ï¸âƒ£ **Receive an answer based on *Meditations* by Marcus Aurelius.**  

---

## **ğŸŒ Environment Variables**
The project requires the following **.env** variables (not included in the repo):
```env
GOOGLE_API_KEY=your_google_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENV=us-east1-gcp
PINECONE_INDEX=marcoaurelio
```

## API Endpoints

The chatbot API provides endpoints for querying the RAG model:

- POST /chat - Sends a user query and retrieves an AI-generated response.

- POST /ingest - Indexes new documents into the vector database.

## Technology Stack & Relevant Expertise

This project demonstrates expertise in:

### Backend Development

- FastAPI: Async API development with dependency injection and Pydantic validation.

- Docker & Docker Compose: Containerization for seamless deployment.


### AI & NLP

- LangChain: LLM orchestration with advanced prompt engineering.

- OpenAI API: Integration of GPT-based language models.

- Pinecone: High-performance vector search for information retrieval.

### DevOps & Cloud

- Containerization: Deployment-ready with Docker.

- Scalability: Microservices-based architecture ensuring extensibility.

- Cloud AI Integration: Leveraging cloud-based AI APIs for enhanced performance.





